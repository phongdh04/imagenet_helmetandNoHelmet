# =============================================================================
# CREATE_VISUALIZATIONS.PY - T·∫†O ·∫¢NH MINH H·ªåA CHO README
# =============================================================================
# M·ª•c ƒë√≠ch: T·∫°o c√°c bi·ªÉu ƒë·ªì v√† ·∫£nh minh h·ªça cho README
# Output: C√°c file ·∫£nh trong th∆∞ m·ª•c images/
# =============================================================================

import matplotlib.pyplot as plt
import numpy as np
import matplotlib.patches as patches
from matplotlib.patches import Rectangle
import seaborn as sns

# C·∫•u h√¨nh font cho ti·∫øng Vi·ªát
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

def create_dataset_overview():
    """T·∫°o bi·ªÉu ƒë·ªì t·ªïng quan dataset"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Bi·ªÉu ƒë·ªì c·ªôt s·ªë l∆∞·ª£ng ·∫£nh
    categories = ['C√≥ M≈© B·∫£o Hi·ªÉm', 'Kh√¥ng C√≥ M≈© B·∫£o Hi·ªÉm']
    counts = [652, 653]
    colors = ['#2E8B57', '#DC143C']
    
    bars = ax1.bar(categories, counts, color=colors, alpha=0.8)
    ax1.set_title('Ph√¢n B·ªë Dataset', fontsize=16, fontweight='bold')
    ax1.set_ylabel('S·ªë L∆∞·ª£ng ·∫¢nh', fontsize=12)
    ax1.set_ylim(0, 700)
    
    # Th√™m s·ªë li·ªáu tr√™n c·ªôt
    for bar, count in zip(bars, counts):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 5,
                f'{count}', ha='center', va='bottom', fontweight='bold')
    
    # Bi·ªÉu ƒë·ªì tr√≤n t·ª∑ l·ªá
    ax2.pie(counts, labels=categories, colors=colors, autopct='%1.1f%%',
            startangle=90, explode=(0.05, 0.05))
    ax2.set_title('T·ª∑ L·ªá Ph√¢n B·ªë', fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('images/dataset_overview.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("‚úÖ ƒê√£ t·∫°o: dataset_overview.png")

def create_training_progress():
    """T·∫°o bi·ªÉu ƒë·ªì ti·∫øn tr√¨nh hu·∫•n luy·ªán"""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
    
    # D·ªØ li·ªáu m√¥ ph·ªèng t·ª´ 4 l·∫ßn ƒëi·ªÅu ch·ªânh
    epochs = np.arange(1, 26)
    
    # L·∫ßn 1: Overfitting nghi√™m tr·ªçng
    train_acc1 = np.linspace(0.7, 0.95, 25)
    val_acc1 = np.linspace(0.7, 0.8, 25) + np.random.normal(0, 0.02, 25)
    
    ax1.plot(epochs, train_acc1, 'b-', linewidth=2, label='Training Accuracy')
    ax1.plot(epochs, val_acc1, 'r-', linewidth=2, label='Validation Accuracy')
    ax1.set_title('L·∫ßn 1: M√¥ h√¨nh ban ƒë·∫ßu\n(Overfitting nghi√™m tr·ªçng)', fontweight='bold')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # L·∫ßn 2: Th√™m Regularization
    train_acc2 = np.linspace(0.7, 0.85, 25)
    val_acc2 = np.linspace(0.7, 0.8, 25) + np.random.normal(0, 0.01, 25)
    
    ax2.plot(epochs, train_acc2, 'b-', linewidth=2, label='Training Accuracy')
    ax2.plot(epochs, val_acc2, 'r-', linewidth=2, label='Validation Accuracy')
    ax2.set_title('L·∫ßn 2: Th√™m Regularization', fontweight='bold')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    # L·∫ßn 3: ƒêi·ªÅu ch·ªânh Augmentation
    train_acc3 = np.linspace(0.7, 0.84, 25)
    val_acc3 = np.linspace(0.7, 0.77, 25) + np.random.normal(0, 0.015, 25)
    
    ax3.plot(epochs, train_acc3, 'b-', linewidth=2, label='Training Accuracy')
    ax3.plot(epochs, val_acc3, 'r-', linewidth=2, label='Validation Accuracy')
    ax3.set_title('L·∫ßn 3: ƒêi·ªÅu ch·ªânh Augmentation', fontweight='bold')
    ax3.set_xlabel('Epoch')
    ax3.set_ylabel('Accuracy')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # L·∫ßn 4: Two-stage Training
    train_acc4 = np.linspace(0.7, 0.9, 25)
    val_acc4 = np.linspace(0.7, 0.83, 25) + np.random.normal(0, 0.01, 25)
    
    ax4.plot(epochs, train_acc4, 'b-', linewidth=2, label='Training Accuracy')
    ax4.plot(epochs, val_acc4, 'r-', linewidth=2, label='Validation Accuracy')
    ax4.set_title('L·∫ßn 4: Two-stage Training\n(K·∫øt qu·∫£ t·ªëi ∆∞u)', fontweight='bold')
    ax4.set_xlabel('Epoch')
    ax4.set_ylabel('Accuracy')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('images/training_progress.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("‚úÖ ƒê√£ t·∫°o: training_progress.png")

def create_model_architecture():
    """T·∫°o s∆° ƒë·ªì ki·∫øn tr√∫c m√¥ h√¨nh"""
    fig, ax = plt.subplots(1, 1, figsize=(12, 8))
    
    # V·∫Ω c√°c kh·ªëi c·ªßa m√¥ h√¨nh
    y_positions = [0.9, 0.7, 0.5, 0.3, 0.1]
    labels = ['Input Image\n(128√ó128√ó3)', 'MobileNetV2\n(Base Model)', 'Global Average\nPooling', 'Dense + Dropout\n(128 units)', 'Output\n(Sigmoid)']
    colors = ['#FFE4B5', '#87CEEB', '#98FB98', '#DDA0DD', '#F0E68C']
    
    for i, (y, label, color) in enumerate(zip(y_positions, labels, colors)):
        rect = Rectangle((0.1, y-0.08), 0.8, 0.15, linewidth=2, 
                        edgecolor='black', facecolor=color, alpha=0.7)
        ax.add_patch(rect)
        ax.text(0.5, y, label, ha='center', va='center', fontsize=12, fontweight='bold')
        
        # V·∫Ω m≈©i t√™n k·∫øt n·ªëi
        if i < len(y_positions) - 1:
            ax.arrow(0.5, y-0.08, 0, -0.1, head_width=0.02, head_length=0.02, 
                    fc='black', ec='black')
    
    # Th√™m ch√∫ th√≠ch
    ax.text(0.5, 0.95, 'Ki·∫øn Tr√∫c M√¥ H√¨nh MobileNetV2', 
            ha='center', va='center', fontsize=16, fontweight='bold')
    
    # Th√™m th√¥ng tin chi ti·∫øt
    details = [
        "‚Ä¢ Transfer Learning t·ª´ ImageNet",
        "‚Ä¢ Fine-tuning 20 layers cu·ªëi",
        "‚Ä¢ Dropout (0.5) + L2 Regularization (0.001)",
        "‚Ä¢ Binary Classification (C√≥/Kh√¥ng c√≥ m≈© b·∫£o hi·ªÉm)"
    ]
    
    for i, detail in enumerate(details):
        ax.text(0.02, 0.02 - i*0.03, detail, fontsize=10, 
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgray", alpha=0.7))
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('images/model_architecture.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("‚úÖ ƒê√£ t·∫°o: model_architecture.png")

def create_performance_comparison():
    """T·∫°o bi·ªÉu ƒë·ªì so s√°nh hi·ªáu su·∫•t"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Bi·ªÉu ƒë·ªì c·ªôt so s√°nh accuracy
    iterations = ['L·∫ßn 1', 'L·∫ßn 2', 'L·∫ßn 3', 'L·∫ßn 4']
    train_acc = [95, 85, 84, 90]
    val_acc = [80, 80, 77, 83]
    
    x = np.arange(len(iterations))
    width = 0.35
    
    bars1 = ax1.bar(x - width/2, train_acc, width, label='Training Accuracy', 
                    color='skyblue', alpha=0.8)
    bars2 = ax1.bar(x + width/2, val_acc, width, label='Validation Accuracy', 
                    color='lightcoral', alpha=0.8)
    
    ax1.set_xlabel('L·∫ßn ƒêi·ªÅu Ch·ªânh Tham S·ªë')
    ax1.set_ylabel('Accuracy (%)')
    ax1.set_title('So S√°nh Hi·ªáu Su·∫•t Qua C√°c L·∫ßn T·ªëi ∆Øu', fontweight='bold')
    ax1.set_xticks(x)
    ax1.set_xticklabels(iterations)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Th√™m s·ªë li·ªáu tr√™n c·ªôt
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{height}%', ha='center', va='bottom', fontsize=10)
    
    # Bi·ªÉu ƒë·ªì overfitting gap
    gaps = [15, 5, 7, 7]  # Kho·∫£ng c√°ch gi·ªØa training v√† validation
    
    bars3 = ax2.bar(iterations, gaps, color=['red', 'orange', 'yellow', 'green'], alpha=0.7)
    ax2.set_xlabel('L·∫ßn ƒêi·ªÅu Ch·ªânh Tham S·ªë')
    ax2.set_ylabel('Overfitting Gap (%)')
    ax2.set_title('Kho·∫£ng C√°ch Overfitting', fontweight='bold')
    ax2.grid(True, alpha=0.3)
    
    # Th√™m s·ªë li·ªáu tr√™n c·ªôt
    for bar, gap in zip(bars3, gaps):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.2,
                f'{gap}%', ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('images/performance_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("‚úÖ ƒê√£ t·∫°o: performance_comparison.png")

def create_workflow_diagram():
    """T·∫°o s∆° ƒë·ªì quy tr√¨nh l√†m vi·ªác"""
    fig, ax = plt.subplots(1, 1, figsize=(14, 10))
    
    # ƒê·ªãnh nghƒ©a c√°c b∆∞·ªõc
    steps = [
        "Thu th·∫≠p d·ªØ li·ªáu\n(Kaggle + Roboflow)",
        "Ti·ªÅn x·ª≠ l√Ω\n(Resize + Augmentation)",
        "X√¢y d·ª±ng m√¥ h√¨nh\n(MobileNetV2)",
        "Hu·∫•n luy·ªán\n(Two-stage Training)",
        "ƒê√°nh gi√°\n(Validation)",
        "T·ªëi ∆∞u h√≥a\n(4 l·∫ßn ƒëi·ªÅu ch·ªânh)",
        "K·∫øt qu·∫£ cu·ªëi\n(83% Accuracy)"
    ]
    
    # V·ªã tr√≠ c√°c b∆∞·ªõc
    positions = [(0.1, 0.8), (0.3, 0.8), (0.5, 0.8), (0.7, 0.8), 
                 (0.9, 0.8), (0.5, 0.4), (0.5, 0.1)]
    
    colors = ['#FFE4B5', '#87CEEB', '#98FB98', '#DDA0DD', '#F0E68C', '#FFB6C1', '#32CD32']
    
    for i, (step, pos, color) in enumerate(zip(steps, positions, colors)):
        # V·∫Ω kh·ªëi
        rect = Rectangle((pos[0]-0.08, pos[1]-0.08), 0.16, 0.16, 
                        linewidth=2, edgecolor='black', facecolor=color, alpha=0.7)
        ax.add_patch(rect)
        ax.text(pos[0], pos[1], step, ha='center', va='center', 
                fontsize=10, fontweight='bold', wrap=True)
        
        # V·∫Ω m≈©i t√™n k·∫øt n·ªëi
        if i < len(positions) - 1:
            if i < 4:  # K·∫øt n·ªëi ngang
                ax.arrow(pos[0]+0.08, pos[1], 0.14, 0, head_width=0.02, head_length=0.02, 
                        fc='black', ec='black')
            elif i == 4:  # M≈©i t√™n xu·ªëng
                ax.arrow(pos[0], pos[1]-0.08, 0, -0.22, head_width=0.02, head_length=0.02, 
                        fc='black', ec='black')
            elif i == 5:  # M≈©i t√™n xu·ªëng cu·ªëi
                ax.arrow(pos[0], pos[1]-0.08, 0, -0.22, head_width=0.02, head_length=0.02, 
                        fc='black', ec='black')
    
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)
    ax.axis('off')
    
    # Th√™m ti√™u ƒë·ªÅ
    ax.text(0.5, 0.95, 'Quy Tr√¨nh Ph√°t Tri·ªÉn D·ª± √Ån', 
            ha='center', va='center', fontsize=16, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig('images/workflow_diagram.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("‚úÖ ƒê√£ t·∫°o: workflow_diagram.png")

def main():
    """H√†m ch√≠nh t·∫°o t·∫•t c·∫£ ·∫£nh minh h·ªça"""
    print("üîÑ ƒêang t·∫°o c√°c ·∫£nh minh h·ªça cho README...")
    
    create_dataset_overview()
    create_training_progress()
    create_model_architecture()
    create_performance_comparison()
    create_workflow_diagram()
    
    print("\nüéâ Ho√†n th√†nh t·∫°o ·∫£nh minh h·ªça!")
    print("üìÅ C√°c file ƒë√£ ƒë∆∞·ª£c l∆∞u trong th∆∞ m·ª•c: images/")
    print("\nüìù ƒê·ªÉ th√™m ·∫£nh v√†o README, s·ª≠ d·ª•ng:")
    print("![M√¥ t·∫£](images/t√™n_file.png)")

if __name__ == "__main__":
    main()
